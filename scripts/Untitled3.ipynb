{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-c8f9cfe4f454>:87: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  house_temp = pd.concat([house_temp, house_temp_], 0)\n",
      "<ipython-input-29-c8f9cfe4f454>:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  house_temp['Available'] = house_temp['Available'].str.replace(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Who: Ericson Mattoso\n",
    "    When: 04/nov/2021\n",
    "    What: This script is responsable calculate houses priority\n",
    "    Why: This calculation will help users to find a best deal house\n",
    "    Where: data comes from previous dataframes. \n",
    "    How: calculates based a weighted variables\n",
    "    todo: moving processed files that should be on raw\n",
    "\"\"\"\n",
    "\n",
    "# libs\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "today = date.today()\n",
    "\n",
    "# read data\n",
    "df_pararius = pd.read_csv(\n",
    "    '../data/processed/df_coo_pararius.csv', index_col=[0])\n",
    "house_temp = pd.read_csv('../data/raw/house_temp.csv', index_col=[0])\n",
    "\n",
    "# get unique urls in each dataframe\n",
    "temp1 = df_pararius['url'].unique()\n",
    "temp2 = house_temp['url'].unique()\n",
    "\n",
    "# get only new links that are not saved on our database\n",
    "urls = list(set(temp1) - set(temp2))\n",
    "\n",
    "# Print how many new urls we have now. This is the number of links we need to scrape\n",
    "print(len(urls))\n",
    "\n",
    "\n",
    "def key_val(text):\n",
    "    part = html_soup.find(\"dt\", text=text)\n",
    "    key = (part.text.strip())\n",
    "    val = (part.findNext(\"dd\").text.strip())\n",
    "    return key, val\n",
    "\n",
    "\n",
    "def scrape_web(url):\n",
    "    \"\"\"\n",
    "        the purpose of the function is to scrape a page\n",
    "        it creates fake browser to do not getting blocked\n",
    "        then it transform the html into a string value\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=%s\" % \"1,1\")\n",
    "    driver = webdriver.Chrome(\n",
    "        'temp/chromedriver', chrome_options=chrome_options)\n",
    "    driver.set_window_position(-10000, 0)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    html_soup = BeautifulSoup(html)\n",
    "    driver.close()\n",
    "    return html_soup, 'hdr'\n",
    "\n",
    "\n",
    "# variables\n",
    "not_available = []\n",
    "description_2 = []\n",
    "# This is going in each page to save the dates of\n",
    "i = 0\n",
    "\n",
    "for url in urls:\n",
    "    # flag\n",
    "    print(\">>>>>>>>>\", i, url)\n",
    "    description_1 = {}\n",
    "    try:\n",
    "        html_soup, hdr = scrape_web(url)\n",
    "        key1, val1 = key_val(\"Offered since\")\n",
    "        key2, val2 = key_val(\"Available\")\n",
    "        description_1.update({\n",
    "            'url': url,\n",
    "            key1: val1,\n",
    "            key2: val2,\n",
    "        })\n",
    "        description_2.append(description_1)\n",
    "        i = i+1\n",
    "        print('done')\n",
    "        print()\n",
    "    except:\n",
    "        print('error')\n",
    "        pass\n",
    "house_temp_ = pd.DataFrame(description_2)\n",
    "house_temp = pd.concat([house_temp, house_temp_], 0)\n",
    "\n",
    "\n",
    "def fixing_time_delta(df, time, my_ofset):\n",
    "    \"\"\"\n",
    "        this function will get and transform string into date format\n",
    "    \"\"\"\n",
    "    # if contains week or month\n",
    "    fixing_time_delta = df.loc[df['Offered since'].str.contains(\n",
    "        time, na=False), 'Offered since']\n",
    "    # removing unwanted char\n",
    "    fixing_time_delta = fixing_time_delta.str.replace(\n",
    "        \"\\D\", \"\", regex=True).astype(int)\n",
    "    # calculate when posted vs today\n",
    "    fixing_time_delta = today - fixing_time_delta.apply(my_ofset)\n",
    "    # formating date\n",
    "    fixing_time_delta = pd.to_datetime(\n",
    "        fixing_time_delta).dt.strftime('%d-%m-%Y')\n",
    "    # replace date\n",
    "    df.loc[df['Offered since'].str.contains(\n",
    "        time, na=False), 'Offered since'] = fixing_time_delta\n",
    "    return df\n",
    "\n",
    "\n",
    "# applying function\n",
    "try:\n",
    "    house_temp = fixing_time_delta(house_temp, \"week\", pd.offsets.Week)\n",
    "    house_temp = fixing_time_delta(house_temp, \"month\", pd.offsets.MonthBegin)\n",
    "except:\n",
    "    print('erro')\n",
    "    pass\n",
    "\n",
    "# removing unwanted char\n",
    "house_temp['Available'] = house_temp['Available'].str.replace(\"From\", \"\")\n",
    "# removing unwanted char\n",
    "house_temp['Available'] = house_temp['Available'].str.replace(\n",
    "    \"Immediately|In consultation\", str(today))\n",
    "# formating char\n",
    "house_temp['Available'] = pd.to_datetime(\n",
    "    house_temp['Available']).dt.strftime('%d-%m-%Y')\n",
    "# remove duplicates\n",
    "house_temp = house_temp.drop_duplicates(subset=['url']).reset_index(drop=True)\n",
    "# save results into original df\n",
    "result = pd.merge(df_pararius, house_temp, how='left', on='url')\n",
    "\n",
    "# save only certain columns\n",
    "result2 = result[[\n",
    "    'deal',\n",
    "    'garden-surface-area',\n",
    "    'img',\n",
    "    'price',\n",
    "    'link',\n",
    "    'agency',\n",
    "    'surface-area',\n",
    "    'interior',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'number-of-rooms',\n",
    "    'Plaats',\n",
    "    'Provincie',\n",
    "    'url',\n",
    "    'date',\n",
    "    'status',\n",
    "    'irl',\n",
    "    'image',\n",
    "    'address',\n",
    "    'street',\n",
    "    'Offered since',\n",
    "    'Available',\n",
    "]]\n",
    "# rename columns\n",
    "result2 = result2.rename(columns={\n",
    "    'img': 'Add',\n",
    "    'price': 'Price',\n",
    "    'Plaats': 'City',\n",
    "    'surface-area': 'Area',\n",
    "    'number-of-rooms': 'Rooms',\n",
    "    'garden-surface-area': 'Garden',\n",
    "    'Offered since': 'Offered',\n",
    "    'Available': 'Available', })\n",
    "# Save\n",
    "result2.to_csv('../data/processed/df_coo_pararius.csv')\n",
    "house_temp.to_csv('../data/raw/house_temp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price', 'address', 'street', 'agency', 'irl', 'image', 'Area',\n",
       "       'status', 'Rooms', 'interior', 'construction-period', 'Garden',\n",
       "       'plot-size', 'postcode', 'date', 'latitude', 'longitude', 'Straat',\n",
       "       'Netnummer', 'Postcodenummer', 'Buurt', 'Wijk', 'City', 'Gemeente',\n",
       "       'Provincie', 'Straten', 'url', 'link', 'Add', 'train', 'deal',\n",
       "       'Offered', 'Available'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['deal', 'Garden', 'Add', 'Price', 'link', 'agency', 'Area', 'interior',\n",
       "       'latitude', 'longitude', 'Rooms', 'City', 'Provincie', 'url', 'date',\n",
       "       'status', 'irl', 'image', 'address', 'street', 'Offered', 'Available'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pararius = pd.read_csv('../data/processed/df_coo_pararius.csv', index_col=[0])\n",
    "df_pararius.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
